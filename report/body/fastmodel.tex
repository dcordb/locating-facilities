\subsection{FastModel}

\newcommand{\suma}[2]{ \sum_{#1 = 1}^{ \abs{#2} } }

\begin{flalign}
    & \min f_A(X, Y) - f_B(X, Y) &
    \label{fastmodel}
\end{flalign}
Sujeto a:
\begin{eqnarray*}
    f_A(X, Y) &=& \suma{i}{A} w(A_i) \cdot \left[ \abs{X(A_i) - X} + \abs{Y(A_i) - Y}\right] \\
    f_B(X, Y) &=& \suma{j}{B} w(B_j) \cdot \left[ \abs{X(B_j) - X} + \abs{Y(B_j) - Y}\right] \\
    x_1 \le &X& \le x_2 \\
    y_1 \le &Y& \le y_2
\end{eqnarray*}

Este modelo opta por minimizar la diferencia entre la ``cercanía'' y ``lejanía'' de las instalaciones al punto solución.

\subsection{Resolviendo FastModel}

\begin{proposition}
    Podemos minimizar \eqref{fastmodel} minimizando los términos con $X$ y con $Y$ de forma independiente.
    \label{def_ind}
\end{proposition}

\begin{proof}
    Si separamos por coordenadas en \eqref{fastmodel}, nos queda:

    \begin{eqnarray*}
        S_1(X) &=& \suma{i}{A} w(A_i) \cdot \abs{X(A_i) - X} - \suma{j}{B} w(B_j) \cdot \abs{X(B_j) - X} \\
        S_2(Y) &=& \suma{i}{A} w(A_i) \cdot \abs{Y(A_i) - Y} - \suma{j}{B} w(B_j) \cdot \abs{Y(B_j) - Y} \\
    \end{eqnarray*}

    por tanto \eqref{fastmodel} equivale a $\min \{ S_1(X) + S_2(Y) \}$, que lo logramos minimizando cada término por separado.
    \renewcommand{\qedsymbol}{}
\end{proof}

\begin{definition}
    Para todo $i, j$ $(1 \le i \le \abs{A}, 1 \le j \le \abs{B})$:

    \begin{enumerate}
        \item Un conjunto $T_x$ es de puntos originales para la coordenada $x$ si $T_x = \{ X(A_i), X(B_j), x_1, x_2 \}$.
        \item Un conjunto $T_y$ es de puntos originales para la coordenada $y$ si $T_y = \{ Y(A_i), Y(B_j), y_1, y_2 \}$.
    \end{enumerate}

\end{definition}

\begin{definition}
    Sean $k = \abs{T_x}$, $e_1 \le e_2 \le \ldots \le e_k$ los elementos de $T_x$ definimos los intervalos de $T_x$ como $I_{i} = [ e_i, e_{i+1}]$ para todo $i$ $(1 \le i < k)$.
    \label{d:intervalos}
\end{definition}

\begin{collorary}
    Sea $I_i = [e_i, e_{i+1}]$ un intervalo de $T_x$, para todo $i$ $(1 \le i < k)$ se cumple que no existe $t \in T_x \cap (e_i, e_{i+1})$. \footnote{Informalmente esto significa que los únicos elementos de $T_x$ que están en $I_i$ son los extremos de dicho intervalo.}
    \label{C:1}
\end{collorary}

\begin{proof}
    La demostración es directa por la definición de los intervalos (Def. \ref{d:intervalos}).
\end{proof}

\begin{collorary}
    $\displaystyle \bigcup_{i=1}^{k-1} I_i = [x_1, x_2]$.
    \label{C:2}
\end{collorary}

\begin{proof}
    La demostración es directa por la definición de los intervalos (Def. \ref{d:intervalos}).
\end{proof}

\begin{proposition}
    Sea $I$ un intervalo de $T_x$, para todo $x \in I$ se cumple que $S_1(x)$ es una función lineal que depende de $x$.
    \label{def_fnok}
\end{proposition} 

\begin{proof}
    \hfill

    Denotemos a:

    \begin{itemize}[label=\textbullet]
        \item $m(x) = \{ X(A_i) \mid X(A_i) < x \} \cup \{ X(B_j) \mid X(B_j) < x \}$
        \item $M(x) = \{ X(A_i) \mid X(A_i) > x \} \cup \{ X(B_j) \mid X(B_j) > x \}$
    \end{itemize}

    Por el Colorario~\ref{C:1} sabemos que $m(x)$ y $M(x)$ no cambian en $I$. Lo que nos permite quitarnos el valor absoluto de las sumas. Al hacer esto, agrupamos los términos con y sin $x$, obteniendo una función lineal.
    \label{P:linear}
\end{proof}

\begin{proposition}
    Sea $I_i = [e_i, e_{i+1}]$ un intervalo de $T_x$, para todo $x \in I_i$ se cumple que $\min \{ S_1(e_i), S_1(e_{i+1}) \} \le S_1(x)$.
    \label{def_mn}
\end{proposition}

\begin{proof}
    Usando la Prop.~\ref{def_fnok} sabemos que $S_1(x)$ se puede expresar como $m \cdot x + n$.

    Analicemos tres casos:

    \begin{enumerate}
        \item Si $m > 0 \implies S_1(x)$ se minimiza en $e_i$.
        \item Si $m < 0 \implies S_1(x)$ se minimiza en $e_{i+1}$.
        \item Si $m = 0 \implies S_1(x)$ se minimiza en cualquier $t \in I_i$ (en particular en $e_i$ o en $e_{i+1}$).
    \end{enumerate}

    Por lo que queda demostrado.
\end{proof}

\begin{proposition}
    Existe un punto solución $(X, Y)$ tal que $X \in T_x$, $Y \in T_y$, $x_1 \le X \le x_2$ y $y_1 \le Y \le y_2$.
    \label{def_sol}
\end{proposition}

\begin{proof}
    \hfill

    Por la Prop.~\ref{def_ind} sabemos que la coordenada $x$ es independiente de la $y$, lo que nos permite minimizar $X$ y $Y$ por separado. Sin pérdida de generalidad demostremos que $X$ es solución, ya que $Y$ es un caso simétrico.
    
    Supongamos que $X$ no pertenece a $T_x$, entonces existe un intervalo $I_i$ de $T_x$ al cual $X$ pertenece. Esto es obvio dado que $x_1 \le X \le x_2$ y por lo obtenido en el Colorario \ref{C:2}.
    
    Luego por la Prop.~\ref{def_mn} nos encontramos en una contradicción, dado que encontramos un óptimo con valor menor o igual a $S_1(X)$ que sí pertenece a $T_x$.
    
    Por lo que $X$ tiene que pertenecer a $T_x$.
\end{proof}

Ahora por la Prop.~\ref{def_sol} nuestro problema se reduce a evaluar cada elemento del conjunto $T_x$ y $T_y$ en $S_1$ y $S_2$ respectivamente.

\subsubsection{Hallando el óptimo}

Vamos a mostrar como evaluar $S_1(X)$, ya que $S_2(Y)$ es simétrico.

En primer lugar ordenamos el conjunto $A$ por su coordenada $x$. Denotemos como $L$ al miembro izquierdo de $S_1(X)$ y como $R$ al miembro derecho.

Definimos $p$ como la menor posición $i$ $(1 \le i \le |A|)$ tal que $X(A_i) > X$. Entonces se cumple que:

\begin{eqnarray*}
    L_1 &=& X \cdot (w(A_1) + \ldots + w(A_{p-1})) - X(A_1) \cdot w(A_1) - \ldots - X(A_{p-1}) \cdot w(A_{p-1}) \\
    L_2 &=& -X \cdot (w(A_p) + \ldots + w(A_{\abs{A}})) + X(A_p) \cdot w(A_p) + \ldots + X(A_{\abs{A}}) \cdot w(A_{\abs{A}}) \\
    L &=& L_1 + L_2
\end{eqnarray*}

En otras palabras, las coordenadas $x$ de las instalaciones $i$ $(1 \le i < p)$ son todas menores o iguales a $X$ y el resto son mayores, por lo que podemos quitarnos el valor absoluto. Para $R$ nos queda algo similar. Notar que esto es lo que nos queda luego de desarrollar la demostración de la Prop.~\ref{def_fnok} (solo teniendo en cuenta $L$).

Ahora solo tenemos que fijar un $X \in T_x$, hay $O(n)$ de ellos, donde $n = \abs{T_x} = \abs{A} + \abs{B} + 2$; y hallar $L$ y $R$. Dado un $X$ fijo podemos hallar el costo correspondiente en $O(\log n )$, porque solo tenemos que buscar $p$ con una búsqueda binaria; y para hallar el costo podemos precalcular sumas acumulativas que nos van a permitir hallar la suma en un rango en $O(1)$. \footnote{Más detalles sobre esto se pueden ver en el código.} Por lo que podemos resolver el modelo en $O(n \log n)$.

\textbf{Es importante notar la eficiencia de la solución obtenida; es un $O(n \log n)$ con una constante muy baja. Esta solución funciona muy rápido para conjuntos de puntos en el orden de $10^7$ elementos.}